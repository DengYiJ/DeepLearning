# -*- coding: utf-8 -*-
"""Image Classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15hMu9YiYjE_6HY99UXon2vKGk2KwugWu

# Get Data
Notes: if the links are dead, you can download the data directly from Kaggle and upload it to the workspace, or you can use the Kaggle API to directly download the data into colab.
"""

#! wget https://www.dropbox.com/s/6l2vcvxl54b0b6w/food11.zip
#! wget -O food11.zip "https://github.com/virginiakm1988/ML2022-Spring/blob/main/HW03/food11.zip?raw=true"
# 
#! unzip food11.zip

_exp_name = "sample"
OS = "Windows"

# Import necessary packages.
import numpy as np
import torch
import os
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image
# "ConcatDataset" and "Subset" are possibly useful when doing semi-supervised learning.
from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset
from torchvision.datasets import DatasetFolder, VisionDataset
import torchvision
# This is for the progress bar.
from tqdm.auto import tqdm
import random
from torchvision.transforms import v2
myseed = 6666  # set a random seed for reproducibility
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
np.random.seed(myseed)
torch.manual_seed(myseed)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(myseed)

"""## **Transforms**
Torchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.
这段文档字符串说明了 torchvision 提供了许多有用的工具，用于图像预处理、数据包装和数据增强。用户被建议查看 PyTorch 官方网站以获取不同转换的详细信息。
Please refer to PyTorch official website for details about different transforms.
"""

# Normally, We don't need augmentations in testing and validation.
# All we need here is to resize the PIL image and transform it into Tensor.
test_tfm = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),#将调整后的图像转换为 PyTorch 的张量格式。这是因为 PyTorch 模型通常需要输入为张量。
])

# However, it is also possible to use augmentation in the testing phase.
# You may use train_tfm to produce a variety of images and then test using ensemble methods
train_tfm = transforms.Compose([

    # Resize the image into a fixed shape (height = width = 128)
    transforms.Resize((128, 128)),
    # You may add some transforms here.进行了图片增强
    #transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),
   # v2.RandomHorizontalFlip(p=0.5),
    #v2.ToDtype(torch.float32, scale=True),
 #  transforms.ColorJitter(brightness=1, contrast=1, saturation=1, hue=0.5),
    transforms.ToTensor(),
    # 进行归一化和标准化，Imagenet数据集的均值和方差为：mean=(0.485, 0.456, 0.406)，std=(0.229, 0.224, 0.225)，
    # 因为这是在百万张图像上计算而得的，所以我们通常见到在训练过程中使用它们做标准化。
  #  transforms.Normalize(mean=[0.406, 0.456, 0.485], std=[0.225, 0.224, 0.229]),
    # #这行代码表示使用transforms.RandomErasing函数，以概率p=1，在图像上随机选择一个尺寸为scale=(0.02, 0.33)，长宽比为ratio=(1, 1)的区域，
    # #进行随机像素值的遮盖，只能对tensor操作：
#    transforms.RandomErasing(p=0.1, scale=(0.02, 0.2), ratio=(1, 1), value='random')
    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    # ToTensor() should be the last one of the transforms.
])

"""## **Datasets**
The data is labelled by the name, so we load images and label while calling '__getitem__'
数据是通过文件名进行标记的，因此在调用 __getitem__ 方法时会加载图像和标签。
"""

class FoodDataset(Dataset):

    def __init__(self,path,tfm=test_tfm,files = None):
        super(FoodDataset).__init__()
        self.path = path
        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(".jpg")])#使用列表推导式获取指定路径下所有以 .jpg 结尾的文件，并对文件名进行排序。
        if files != None:
            self.files = files
        print(f"One {path} sample",self.files[0])
        self.transform = tfm

  #返回数据集中图像的数量，即 self.files 列表的长度。
    def __len__(self):
        return len(self.files)
  
    def __getitem__(self,idx):
        fname = self.files[idx]
        im = Image.open(fname)
        im = self.transform(im)
        #im = self.data[idx]
        #使用 try 块来提取标签。标签是通过文件名解析的，假设文件名格式为 label_name.jpg，其中 label 是数字，表示图像的分类。1_105经历提取后是1，0_14经历提取后是0
        try:
            if OS == "Windows":
                label = int(fname.split("\\")[-1].split("_")[0])
            else:
                label = int(fname.split("/")[-1].split("_")[0])
            # print("\n", label)
        except:
            label = -1 # test has no label
            # Mixup逻辑
            # 随机选择另一幅图像
        idx2 = random.randint(0, len(self.files) - 1)
        fname2 = self.files[idx2]
        im2 = Image.open(fname2)
        im2 = self.transform(im2)
            #获取图片2的label
        try:
            if OS == "Windows":
                label2= int(fname2.split("\\")[-1].split("_")[0])
            else:
                label2 = int(fname2.split("/")[-1].split("_")[0])
            #print("\n", label2)
        except:
            label2 = -1  # test has no label
        #print("\n", label2)
            # 生成混合系数
        alpha = np.random.beta(0.2, 0.2)  # 根据 beta 分布生成混合系数
        mixed_image = alpha * im + (1 - alpha) * im2

            # 处理标签为 one-hot 编码
        label_one_hot = torch.zeros(11)
        if label != -1:
            label_one_hot[label] = 1.0
        label_one_hot2 = torch.zeros(11)
        if label2 != -1:
            label_one_hot2[label2] = 1.0  # 将第二幅图像的标签位置设为1

            # 混合标签
        if label != -1 and label2 != -1:  # 确保两个标签都是有效的
            mixed_label = alpha * label_one_hot + (1 - alpha) * label_one_hot2
        else:
            mixed_label = label_one_hot  # 如果其中一个标签无效，使用另一个标签
            #label=mixed_label
           # im=mixed_image
        return mixed_image, mixed_label
       # return im,label
    #验证交叉熵
    def cross_entropy_loss(self, predictions, targets):
        """
        自定义交叉熵损失函数
        :param predictions: 模型的输出，形状为 (batch_size, num_classes)
        :param targets: 目标标签，形状为 (batch_size, num_classes)
        :return: 计算得到的损失值
        """
        # 使用 softmax 计算每个类的概率
        log_probs = torch.log_softmax(predictions, dim=1)
        # 计算交叉熵损失
        loss = -torch.sum(targets * log_probs, dim=1).mean()
        return loss

"""###该 Classifier 类实现了一个典型的卷积神经网络结构，包含多个卷积层、批归一化层、ReLU 激活函数和最大池化层，最后通过全连接层进行分类。
通过这种结构，网络能够有效地提取图像特征并进行多类别分类。
"""
class Classifier(nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        # torch.nn.MaxPool2d(kernel_size, stride, padding)
        # input 維度 [3, 128, 128]   channels,lens,width
        #self.cnn 是一个顺序容器（nn.Sequential），用于按顺序构建网络的各个层
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]，卷积层（nn.Conv2d）第一个参数是输入通道数，第二个参数是输出通道数，第三个参数是卷积核的大小，第四个是步幅，最后一个是填充。
            nn.BatchNorm2d(64),#批归一化层（nn.BatchNorm2d）：用于加速训练并提高稳定性
            nn.ReLU(),#应用 ReLU 激活函数，增加网络的非线性
            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]用于下采样，减小特征图的尺寸。例如，nn.MaxPool2d(2, 2, 0) 表示使用 2x2 的池化窗口，步幅为 2。

            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]

            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]

            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]
            
            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]
            nn.BatchNorm2d(512),
            nn.ReLU(),
          #  nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]
            #guess:太多下采样，使得特征减少，精确度不高，所以最后一层，不用池化了，试试看
            #相应的在下方nn.linear处要改为相应channels，lens，width大小的参数，是512x8x8
        #   再加一层卷积层
       #     nn.Conv2d(512, 512, 3, 1, 1),  # [512, 8, 8]
        #    nn.BatchNorm2d(512),
         #   nn.ReLU(),
        )
        #self.fc 是另一个顺序容器，用于构建全连接层。
        self.fc = nn.Sequential(
            #：第一个全连接层，输入大小为512x4x4，输出大小维持1024
            nn.Linear(512*8*8, 1024),
            nn.ReLU(),
            #nn.Dropout(0.5),  # 添加 Dropout 层
            nn.Linear(1024, 512),
            nn.ReLU(),
            #nn.Dropout(0.5),  # 添加 Dropout 层
            nn.Linear(512, 11)
        )
#forward 方法定义了前向传播的计算过程。
    def forward(self, x):
        out = self.cnn(x)#将输入 x 传递通过卷积网络，得到特征图。
        out = out.view(out.size()[0], -1)#将特征图展平为一维向量，out.size()[0] 是批量大小，-1 表示自动计算剩余维度。
        return self.fc(out)#将展平后的向量传递到全连接层，得到最终输出。

batch_size = 64 #设置批量大小为 64
#现我更改batch为32
_dataset_dir = os.path.join(os.getcwd(), "food11")#构建数据集目录的路径，假设数据集位于当前工作目录下的 food11 文件夹。
# "cuda" only when GPUs are available.
device = "cuda" if torch.cuda.is_available() else "cpu"
# device = "cpu"

def Training_Demo():
    """# Training"""
    # Construct datasets.
    # The argument "loader" tells how torchvision reads the data.在训练demo中读取了训练集和验证集，调用了fooddataset
    #DataLoader: 这是 PyTorch 提供的一个类，用于将数据集分成小批次（batch），以便于在训练过程中逐步加载数据。它可以处理多线程加载和其他优化。
    print(os.path.join(_dataset_dir,"training"))
    train_set = FoodDataset(os.path.join(_dataset_dir,"training"), tfm=train_tfm)#数据集：使用 FoodDataset 类从指定目录加载训练和验证数据集，tfm 参数用于数据增强或预处理。
    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)#数据加载器：使用 DataLoader 来生成批次数据，batch_size 指定每个批次的样本数量，shuffle=True 表示在每个 epoch 开始前打乱数据
    valid_set = FoodDataset(os.path.join(_dataset_dir,"validation"), tfm=test_tfm)
    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)


    # The number of training epochs and patience.
    #训练周期：设置训练的总周期数为 5。
    n_epochs = 5
    patience = 300 # If no improvement in 'patience' epochs, early stop.早停策略：如果在 patience 轮内没有性能提升，则提前停止训练。

    # Initialize a model, and put it on the device specified.实例化 Classifier 类的对象并将其移动到指定设备（如 GPU）。
    model = Classifier().to(device)

    # For the classification task, we use cross-entropy as the measurement of performance.使用交叉熵损失函数，适用于多分类问题。
    #criterion = nn.CrossEntropyLoss()

    # Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.使用 Adam 优化器，设置学习率和权重衰减（L2 正则化）。
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5) 

    # Initialize trackers, these are not parameters and should not be changed
    stale = 0
    best_acc = 0

    for epoch in range(n_epochs):

        # ---------- Training ----------
        # Make sure the model is in train mode before training.
        #在训练前调用 model.train()，启用 dropout 等训练特性。
        model.train()

        # These are used to record information in training.
        train_loss = []
        train_accs = []

#批次迭代：遍历训练数据加载器，获取图像和标签。
        for batch in tqdm(train_loader):

            # A batch consists of image data and corresponding labels.
            imgs, labels = batch
            #imgs = imgs.half()
            #print(imgs.shape,labels.shape)

            # Forward the data. (Make sure data and model are on the same device.)将图像输入模型，得到 logits（未经过 softmax 的输出）。
            logits = model(imgs.to(device))
            labels = labels.to(device)
            # Calculate the cross-entropy loss.计算损失。
            # We don't need to apply softmax before computing cross-entropy as it is done automatically.
            #loss = λ * criterion(outputs, targets_a) + (1 - λ) * criterion(outputs, targets_b)
            #loss = criterion(logits, labels.to(device))
            #你已经在__getitem__方法中实现了将标签转换为 one-hot 编码的逻辑，所以在训练时直接使用返回的标签。
            loss = train_set.cross_entropy_loss(logits,labels.to(device))
            # Gradients stored in the parameters in the previous step should be cleared out first.在每次反向传播前清除上一步的梯度。
            optimizer.zero_grad()

            # Compute the gradients for parameters.计算梯度。
            loss.backward()

            # Clip the gradient norms for stable training.防止梯度爆炸。设置梯度的最大范数为10。如果梯度的范数超过这个值，函数会将其缩放到这个最大值，从而实现裁剪。
            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)

            # Update the parameters with computed gradients.参数更新
            optimizer.step()

            # Compute the accuracy for current batch.
           # acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()
            acc = (logits.argmax(dim=-1) == labels.argmax(dim=-1)).float().mean()

            # Record the loss and accuracy.记录每个批次的损失和准确率。
            train_loss.append(loss.item())
            train_accs.append(acc)
            
        train_loss = sum(train_loss) / len(train_loss)
        train_acc = sum(train_accs) / len(train_accs)

        # Print the information.
        print(f"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}")

        # ---------- Validation ----------
        # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.
        model.eval()

        # These are used to record information in validation.
        valid_loss = []
        valid_accs = []

        # Iterate the validation set by batches.
        for batch in tqdm(valid_loader):#loader将imgs，labels全部加载到设备上

            # A batch consists of image data and corresponding labels.
            imgs, labels = batch
            #imgs = imgs.half()

            # We don't need gradient in validation.
            # Using torch.no_grad() accelerates the forward process.
            with torch.no_grad():
                logits = model(imgs.to(device))
                labels = labels.to(device)
            # We can still compute the loss (but not the gradient).
            loss = valid_set.cross_entropy_loss(logits, labels.to(device))

            # Compute the accuracy for current batch.
            acc = (logits.argmax(dim=-1) == labels.argmax(dim=-1)).float().mean()


            # Record the loss and accuracy.
            valid_loss.append(loss.item())
            valid_accs.append(acc)
            #break

        # The average loss and accuracy for entire validation set is the average of the recorded values.
        valid_loss = sum(valid_loss) / len(valid_loss)
        valid_acc = sum(valid_accs) / len(valid_accs)

        # Print the information.
        print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")


        # update logs
        if valid_acc > best_acc:
            with open(f"./{_exp_name}_log.txt","a"):
                print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best")
        else:
            with open(f"./{_exp_name}_log.txt","a"):
                print(f"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}")


        # save models
        if valid_acc > best_acc:#如果验证准确率超过历史最佳值，则保存模型。
            print(f"Best model found at epoch {epoch}, saving model")
            torch.save(model.state_dict(), f"{_exp_name}_best.ckpt") # only save best to prevent output memory exceed error
            best_acc = valid_acc
            stale = 0
        else:
            stale += 1
            if stale > patience:#如果在 patience 轮内没有提升，则停止训练。
                print(f"No improvment {patience} consecutive epochs, early stopping")
                break
#主要用于在给定的验证数据集上评估训练好的模型的性能
def Testing_Demo():
    valid_set = FoodDataset(os.path.join(_dataset_dir,"validation"), tfm=train_tfm)#用于加载验证集的数据,测试时增强TTA
    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
    model_test = Classifier().to(device)
    model_test.load_state_dict(torch.load(f"{_exp_name}_best.ckpt"))# 加载训练好的模型权重（存储在 _exp_name_best.ckpt 文件中）。
    model_test.eval()#将模型设置为评估模式，这样可以禁用 Dropout 和 Batch Normalization 等训练时的特性。
    #初始化用于存储验证损失、准确率、文件 ID 和预测结果的列表。
    valid_loss = []
    valid_accs = []
    ids = []
    predictions = []

    path = os.path.join(_dataset_dir,"validation")
    files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(".jpg")])
    for fname in files:
        if OS == "Windows":
            ids.append( fname.split("\\")[-1].split(".")[0])
        else:
            ids.append( fname.split("/")[-1].split(".")[0])

    with torch.no_grad():
        for data, labels in tqdm(valid_loader):
            data = data.to(device)  # 将数据移动到设备
            labels = labels.to(device)  # 将标签也移动到设备
            test_pred = model_test(data.to(device))
            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)
            predictions += test_label.squeeze().tolist()
            logits = model_test(data)
            #acc = (test_pred.argmax(dim=-1) == labels).float().mean()
            acc = (logits.argmax(dim=-1) == labels.argmax(dim=-1)).float().mean()
            valid_accs.append(acc)
        #   for data, labels in tqdm(valid_loader):
        #     data = data.to(device)  # 将数据移动到设备
        #     labels = labels.to(device)  # 将标签也移动到设备
        #
        #     # TTA: 对每种变换进行预测
        #     tta_predictions = []
        #     for transform in [train_tfm]:  # 这里可以添加多种变换
        #         transformed_data = transform(data)  # 应用变换
        #         test_pred = model_test(transformed_data)
        #         tta_predictions.append(test_pred)
        #
        #     # 对所有变换的预测结果求平均
        #     avg_pred = torch.mean(torch.stack(tta_predictions), dim=0)
        #     test_label = np.argmax(avg_pred.cpu().data.numpy(), axis=1)
        #     predictions += test_label.squeeze().tolist()

    valid_acc = sum(valid_accs) / len(valid_accs)    #计算所有批次的平均准确率并打印出来。
    print(f"acc = {valid_acc:.5f}")

    if OS == "Windows":
        with open(os.getcwd() + "\\result.txt", "w") as f:
            f.write(f"ID Category Accuracy: {valid_acc}\n")
            for i in range(len(ids)):
                f.write(ids[i])
                f.write(" ")
                f.write(str(predictions[i]))
                f.write("\n")
    else:
        with open("result.txt", "w") as f:
            f.write(f"ID Category Accuracy: {valid_acc}\n")
            for i in range(len(ids)):
                f.write(ids[i])
                f.write(" ")
                f.write(str(predictions[i]))
                f.write("\n")
        

def Predict_demo():
    """# Testing and generate prediction CSV"""
    import pandas as pd
    test_set = FoodDataset(os.path.join(_dataset_dir,"test"), tfm=test_tfm)
    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)
    model_best = Classifier().to(device)
    model_best.load_state_dict(torch.load(f"{_exp_name}_best.ckpt"))
    model_best.eval()
    prediction = []
    with torch.no_grad():
        for data,_ in test_loader:
            test_pred = model_best(data.to(device))
            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)
            prediction += test_label.squeeze().tolist()

    #create test csv
    def pad4(i):
        return "0"*(4-len(str(i)))+str(i)
    df = pd.DataFrame()
    df["Id"] = [pad4(i) for i in range(1,len(test_set)+1)]
    df["Category"] = prediction
    df.to_csv("submission.csv",index = False)

if __name__ == "__main__":
  #Training_Demo()
   Testing_Demo()
